CCL25-Eval任务10：细粒度中文仇恨识别评测
天池竞赛https://tianchi.aliyun.com/competition/entrance/532298/information
任务内容
本次评测任务为细粒度片段级中文仇恨言论识别，基于给定的文本，任务的输入为社交媒体文本，输出为仇恨四元组。
顺序依次为评论对象（Target）、论点（Argument）、目标群体（Targeted Group）、是否仇恨（Hateful）。
具体说明如下：
评论对象（Target）：帖子的评述对象，如一个人或一个群体。当实例无具体目标时设为NULL。
论点（Argument）：包含对评论目标关键论点的信息片段。
目标群体（Targeted Group）：指包含仇恨信息的评论对象-论点对涉及的目标群体。
                           标注的目标群体包括“地域”、“种族”、“性别”、“LGBTQ”、“其他”共5类。
是否仇恨（Hateful）：评论对象-论点对是否构成了对某些群体的仇恨言论。
                    对于非仇恨文本和不包含特定群体的一般攻击性言论，同样需要对目标群体和观点进行抽取，并设为Non-hate。
                    由于样本中可能有多个评论对象，因此可以包含多个四元组。 每个四元组中各个元素之间用" | "分割，并利用 [END] 结尾；
                    如果一条样本中包含多个四元组，不同四元组之间利用 [SEP] 分割。

下面提供两个数据样例：
输入： 你可真是头蠢驴，这都做不好。
输出： 你 | 蠢驴 | non-hate | non-hate [END]
输入： 老黑我是真的讨厌，媚黑的还倒贴。
输出： 老黑 | 讨厌 | Racism | hate [SEP] 媚黑的 | 倒贴 | Racism | hate [END]

将模型对测试集的输出内容按行保存到.txt文件中，如demo.txt文件。

评测数据
本次评测使用的中文仇恨言论四元组抽取数据集收集了贴吧、知乎等国内社交媒体平台的用户评论数据，为每条样本提供了高质量的二元分类标签，并对句子中的评论对象、论点和目标群体进行片段级标注。
该数据集总计8000条中文数据，其中仇恨言论为4935，非仇恨言论为3065条。每条语句均包含一个或多个中文仇恨言论四元组，共计9405个，其中仇恨四元组5949个，非仇恨四元组3456个。

数据集的所有权归大连理工大学信息检索研究室所有。数据集包含有害违规内容示例，均不代表本团队立场。所有资源仅供科学研究使用，严禁商用。

评价指标
评价指标为提交结果和标准答案的硬匹配和软匹配分别的F1分数，以及两种方式的F1分数的平均分。计算方式与机器学习库sklearn一致。

硬匹配： 当且仅当预测四元组的每一个元素都与答案中对应元素完全一致才判断为正确抽取的四元组。

软匹配： 当且仅当预测四元组的 Targeted Group , Hateful 两个元素和标准答案中相对应的两个元素完全一致，
并且预测四元组的 Target ，Argument 两个元素和标准答案中相对应的两个元素的字符串匹配程度超过50% 才判断为正确抽取的四元组。（计算方式为Python 标准库 difflib 模块中的 SequenceMatcher 函数一致）。
